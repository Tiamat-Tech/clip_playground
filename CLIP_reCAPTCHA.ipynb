{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kevinzakka/clip_playground/blob/main/CLIP_reCAPTCHA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QpPbEKLBmyX1"
   },
   "source": [
    "# CLIP reCAPTCHA Solve\n",
    "\n",
    "This Colab notebook demos zero-shot reCAPTCHA solving using CLIP + patch detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "qQOvOhnKQ-Tu"
   },
   "outputs": [],
   "source": [
    "#@title Install dependencies\n",
    "\n",
    "#@markdown Please execute this cell by pressing the _Play_ button \n",
    "#@markdown on the left.\n",
    "\n",
    "#@markdown **Note**: This installs the software on the Colab \n",
    "#@markdown notebook in the cloud and not on your computer.\n",
    "\n",
    "%%capture\n",
    "!pip install ftfy regex tqdm matplotlib bs4\n",
    "!pip install git+https://github.com/openai/CLIP.git\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "import clip\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "caPbAhFlRBwT"
   },
   "outputs": [],
   "source": [
    "#@title Helper functions\n",
    "\n",
    "#@markdown Some helper functions for loading, patchifying and visualizing images.\n",
    "\n",
    "def load_image(img_path, resize=None, pil=False):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    if resize is not None:\n",
    "        image = image.resize((resize, resize))\n",
    "    if pil:\n",
    "        return image\n",
    "    return np.asarray(image).astype(np.float32) / 255.\n",
    "\n",
    "def viz_patches(x, figsize=(20, 20), patch_idx=None, topk=None, t=5):\n",
    "    # x: num_patches, 3, patch_size, patch_size\n",
    "    n = patches.shape[0]\n",
    "    nrows = int(math.sqrt(n))\n",
    "    fig, axes = plt.subplots(nrows, nrows, figsize=figsize)\n",
    "    for i, ax in enumerate(axes.flatten()):            \n",
    "        im = x[i].permute(1, 2, 0).numpy()\n",
    "        im = (im * 255.).round().astype(np.uint8)\n",
    "        if patch_idx is not None and i == patch_idx:\n",
    "            im[0:t] = (255, 0, 0)\n",
    "            im[im.shape[0]-t:] = (255, 0, 0)\n",
    "            im[:, 0:t] = (255, 0, 0)\n",
    "            im[:, im.shape[1]-t:] = (255, 0, 0)\n",
    "        if topk is not None:\n",
    "            if i in topk and i != patch_idx:\n",
    "                im[0:t] = (255, 255, 0)\n",
    "                im[im.shape[0]-t:] = (255, 255, 0)\n",
    "                im[:, 0:t] = (255, 255, 0)\n",
    "                im[:, im.shape[1]-t:] = (255, 255, 0)\n",
    "        ax.imshow(im)\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def patchify(image_path, resolution, patch_size, patch_stride=None, resize=None):\n",
    "    img_tensor = transforms.ToTensor()(load_image(image_path, resolution, True))\n",
    "    if patch_stride is None:\n",
    "        patch_stride = patch_size\n",
    "    patches = img_tensor.unfold(\n",
    "        1, patch_size, patch_stride).unfold(2, patch_size, patch_stride)\n",
    "    patches = patches.reshape(3, -1, patch_size, patch_size).permute(1, 0, 2, 3)\n",
    "    if resize is not None:\n",
    "        patches = F.interpolate(\n",
    "            patches,\n",
    "            (resize, resize),\n",
    "            mode='bicubic',\n",
    "            align_corners=False)\n",
    "    return patches  # N, 3, patch_size, patch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 613
    },
    "id": "xhh8okAuIHP3",
    "outputId": "9ce80a22-8f5c-476d-a9b4-b7a25aa19d88"
   },
   "outputs": [],
   "source": [
    "#@title Query reCAPTCHA API\n",
    "\n",
    "#@markdown You might have to click the *Play* button more than once if the URL\n",
    "#@markdown returns a 404.\n",
    "\n",
    "URL = \"https://www.google.com/recaptcha/api/fallback?k=6LewPtQSAAAAAIvk6kmw1mVSYVUvd2Ev5MpenlHk\"\n",
    "url_contents = urllib.request.urlopen(URL).read()\n",
    "soup = BeautifulSoup(url_contents, \"html\")\n",
    "instruction = soup.find(\"div\", {\"class\": \"rc-imageselect-desc-no-canonical\"}).get_text()\n",
    "caption = instruction.split(' ')[-1]\n",
    "image = soup.find(\"img\", {\"class\": \"fbc-imageselect-payload\"})\n",
    "image_url = f\"https://www.google.com/{image['src']}\"\n",
    "image_path = 'image.png'\n",
    "urllib.request.urlretrieve(image_url, image_path)\n",
    "\n",
    "image_np = load_image(image_path)\n",
    "print(f\"Captcha Image Resolution: {image_np.shape}\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image_np)\n",
    "plt.title(instruction, fontsize=20)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "QuHrrEqXdVmx",
    "outputId": "3bd9e398-9275-4b75-c10f-0283522c82db"
   },
   "outputs": [],
   "source": [
    "#@title Solve\n",
    "\n",
    "clip_model = \"ViT-B/16\" #@param [\"RN50\", \"RN101\", \"RN50x4\", \"RN50x16\", \"ViT-B/32\", \"ViT-B/16\"]\n",
    "topk =  4#@param {type:\"integer\"}\n",
    "\n",
    "# Load CLIP model.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(clip_model, device=device, jit=False)\n",
    "\n",
    "patch_size = model.visual.input_resolution\n",
    "patches = patchify(image_path, 300, 100, resize=model.visual.input_resolution).to(device)\n",
    "text_input = clip.tokenize([instruction]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    patch_embs = model.encode_image(patches).float()\n",
    "    text_embs = model.encode_text(text_input).float()\n",
    "    patch_embs = patch_embs / patch_embs.norm(dim=-1, keepdim=True)\n",
    "    text_embs = text_embs / text_embs.norm(dim=-1, keepdim=True)\n",
    "    sim = patch_embs @ text_embs.t()\n",
    "    idx_max = sim.argmax().item()\n",
    "    topk_values, topk_idxs = torch.topk(sim.flatten(), topk)\n",
    "    topk_idxs = topk_idxs.cpu().numpy().tolist()\n",
    "    print(topk_values)\n",
    "\n",
    "viz_patches(patches.cpu(), figsize=(10, 10), patch_idx=idx_max, topk=topk_idxs, t=int(0.05*patch_size))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CLIP reCAPTCHA",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
